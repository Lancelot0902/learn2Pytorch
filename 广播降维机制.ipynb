{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ebad496",
   "metadata": {},
   "source": [
    "##  广播机制\n",
    "\n",
    "即是张量的size不同，也能利用广播机制来对两个张量进行操作，即广播机制后，两个张量会拥有相同的size。大多数情况下会沿着长度为1的轴作广播。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bcb0ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2]]),\n",
       " tensor([[0, 1]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.arange(3).reshape((3, 1))\n",
    "b = torch.arange(2).reshape((1, 2))\n",
    "a,b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8043aeb",
   "metadata": {},
   "source": [
    "由于a是3行1列的矩阵，b是1行2列的矩阵，普通情况下没办法相加，于是a会沿着列的方向广播，b会沿着行的方向广播，广播时会复制元素，a和b都会变成3×2的矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71202a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 2],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de68ae0d",
   "metadata": {},
   "source": [
    "## 降维\n",
    "默认情况下，调用求和函数会沿所有方向降低张量的维度,使它变为一个标量。\n",
    "也可以指定沿某个轴的方向求和，但是这个轴的方向会在输出形状中消失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "844da274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " torch.Size([5, 4]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20, dtype=torch.float32).reshape(5, 4)\n",
    "A,A.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "130a678b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(190.), torch.Size([]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_A = A.sum()\n",
    "sum_A,sum_A.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42373cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([40., 45., 50., 55.]), torch.Size([4]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_A_axis0 = A.sum(axis=0)\n",
    "sum_A_axis0,sum_A_axis0.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ccf3d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 6., 22., 38., 54., 70.]), torch.Size([5]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_A_axis1 = A.sum(axis=1)\n",
    "sum_A_axis1,sum_A_axis1.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209009e2",
   "metadata": {},
   "source": [
    "可以将sum()中的参数keepdim设置成True来进行非降维求和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3e327fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[40., 45., 50., 55.]]), torch.Size([1, 4]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_A = A.sum(axis=0,keepdim=True)\n",
    "sum_A,sum_A.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4b06ff",
   "metadata": {},
   "source": [
    "由于求和后sum_A依然是两个轴，所以可以进行A/sum_A的操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3770cf27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0222, 0.0400, 0.0545],\n",
       "        [0.1000, 0.1111, 0.1200, 0.1273],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000],\n",
       "        [0.3000, 0.2889, 0.2800, 0.2727],\n",
       "        [0.4000, 0.3778, 0.3600, 0.3455]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A/sum_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e46928b",
   "metadata": {},
   "source": [
    "若不设置keepdim=True，sum_A会损失一个轴，这样A/sum_A就成了非法操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8965212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.ones(2,5,4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00cf614b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 5., 5., 5.],\n",
       "        [5., 5., 5., 5.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.sum(axis = 1)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe486727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.sum(axis = 0)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca5614da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8., 8., 8., 8., 8.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.sum(axis = [0,2])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19a87d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[5., 5., 5., 5.]],\n",
       "\n",
       "        [[5., 5., 5., 5.]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.sum(axis = 1,keepdim = True)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f195fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

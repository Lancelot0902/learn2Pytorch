{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "感知机就是一个二分类问题，多层感知机就是加了隐藏层，目的是能够更好地拟合出函数模型。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import torch\r\n",
    "import d2l as d2l\r\n",
    "from torch import nn\r\n",
    "\r\n",
    "\r\n",
    "batch_size = 256\r\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "num_inputs, num_outputs, num_hiddens = 784, 10, 256\r\n",
    "\r\n",
    "w1 = nn.Parameter(\r\n",
    "    torch.randn(num_inputs, num_hiddens, requires_grad=True) * 0.01)\r\n",
    "b1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=True))\r\n",
    "\r\n",
    "w2 = nn.Parameter(\r\n",
    "    torch.randn(num_hiddens, num_outputs, requires_grad=True) * 0.01)\r\n",
    "b2 = nn.Parameter(torch.zeros(num_outputs, requires_grad=True))\r\n",
    "\r\n",
    "params = [w1, b1, w2, b2]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# 激活函数ReLU\r\n",
    "def relu(X):\r\n",
    "    a = torch.zeros_like(X)\r\n",
    "    return torch.max(X,a)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# 含有一层隐藏层的神经网络模型\r\n",
    "def net(X):\r\n",
    "    X = X.reshape((-1, num_inputs))\r\n",
    "    H = relu(X @ w1 + b1)\r\n",
    "    return (H @ w2 + b2)\r\n",
    "\r\n",
    "\r\n",
    "loss = nn.CrossEntropyLoss()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# 训练\r\n",
    "num_epochs, lr = 10, 0.1\r\n",
    "updater = torch.optim.SGD(params, lr=lr)\r\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, updater)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch： 1, loss： 1.0456, train_acc： 0.638, test_acc： 0.734\n",
      "epoch： 2, loss： 0.5966, train_acc： 0.790, test_acc： 0.764\n",
      "epoch： 3, loss： 0.5176, train_acc： 0.819, test_acc： 0.813\n",
      "epoch： 4, loss： 0.4789, train_acc： 0.831, test_acc： 0.794\n",
      "epoch： 5, loss： 0.4504, train_acc： 0.842, test_acc： 0.808\n",
      "epoch： 6, loss： 0.4346, train_acc： 0.846, test_acc： 0.835\n",
      "epoch： 7, loss： 0.4167, train_acc： 0.853, test_acc： 0.842\n",
      "epoch： 8, loss： 0.4037, train_acc： 0.858, test_acc： 0.846\n",
      "epoch： 9, loss： 0.3936, train_acc： 0.861, test_acc： 0.842\n",
      "epoch： 10, loss： 0.3813, train_acc： 0.865, test_acc： 0.842\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit"
  },
  "interpreter": {
   "hash": "1afac9f31d94eb4bb33e3dfb678ca317679229fb6cdf46f98be1090e60a0b866"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
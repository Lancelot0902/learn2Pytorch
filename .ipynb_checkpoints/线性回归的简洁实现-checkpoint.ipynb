{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性回归的简洁实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import d2l\n",
    "import numpy as np\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2\n",
    "features, labels = d2l.synthetic_data(true_w, true_b, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调用API读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True):     #@save\n",
    "    \"\"\" 构造一个基于Pytorch的数据迭代器 \"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)  # 表明datat_attays是一个元组\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)   # is_train表示是否希望数据迭代器对象在每个迭代周期内打乱数据\n",
    "\n",
    "batch_size = 10\n",
    "data_iter = load_array((features, labels), batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证数据迭代器是否正常工作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.2348, -0.6778],\n",
       "         [ 1.0357, -0.1975],\n",
       "         [-1.1187, -1.4215],\n",
       "         [ 0.0192, -1.5897],\n",
       "         [ 0.1269,  0.0876],\n",
       "         [ 2.5652, -0.4655],\n",
       "         [-0.6237,  0.0599],\n",
       "         [ 0.0806, -1.0334],\n",
       "         [ 0.5170,  2.3261],\n",
       "         [ 0.7248, -1.0568]]),\n",
       " tensor([[ 6.9658],\n",
       "         [ 6.9335],\n",
       "         [ 6.7877],\n",
       "         [ 9.6526],\n",
       "         [ 4.1684],\n",
       "         [10.9116],\n",
       "         [ 2.7545],\n",
       "         [ 7.8775],\n",
       "         [-2.6872],\n",
       "         [ 9.2379]])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(data_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义模型，首先定义一个模型变量net，它是一个Sequential类的实例，Sequential类为串联在一起的多个层定义了一个容器。当给定输入数据，Sequential类实例将数据传入第一层，然后第一层的输出作为第二层的输入，以此类推。\n",
    "\n",
    "我们目前的线性回归模型是只有一层的网络架构，这一单层被称为**全连接层**，因为它的每一个输入都是通过矩阵-向量乘法连接到它的每个输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch中，全连接层在Linear类中定义\n",
    "# 将两个参数传递到nn.Linear中，第一个为输入的特征形状，第二个为输出的特征形状\n",
    "\n",
    "from torch import nn    # nn是神经网络neural network的缩写\n",
    "\n",
    "net = nn.Sequential(nn.Linear(2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化模型参数。\n",
    "\n",
    "net[0]表示选择网络中的第一个图层，即我们的线性全连接层，然后定义权重weight和偏置bias的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data.normal_(0, 0.01)\n",
    "net[0].bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义损失函数。\n",
    "\n",
    "使用的是MSELoss类，默认情况下会返回所有样本损失的均值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义优化算法。\n",
    "\n",
    "Pytorch在optim模块实现了该算法的许多变种。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要优化的参数通过net.parameters()中获得\n",
    "# 小批量随机梯度下降只需要设置lr的值\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1,loss 0.000098\n",
      "epoch 2,loss 0.000097\n",
      "epoch 3,loss 0.000097\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter:\n",
    "        l = loss(net(X), y)\n",
    "        trainer.zero_grad()\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "    l = loss(net(features), labels)\n",
    "    print(f'epoch {epoch + 1},loss {l:f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w的估计误差:  tensor([-0.0003, -0.0007])\n",
      "b的估计误差:  tensor([-0.0002])\n"
     ]
    }
   ],
   "source": [
    "w = net[0].weight.data\n",
    "print('w的估计误差: ', true_w - w.reshape(true_w.shape))\n",
    "b = net[0].bias.data\n",
    "print('b的估计误差: ', true_b - b)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1afac9f31d94eb4bb33e3dfb678ca317679229fb6cdf46f98be1090e60a0b866"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
